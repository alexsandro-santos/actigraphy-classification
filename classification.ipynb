{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('extracted_features.csv')\n",
    "y = pd.read_csv('timeseries_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index = X.pop(X.columns[0]).values\n",
    "y.drop('index',axis=1,inplace=True)\n",
    "y.index = y.pop('id').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "normalized_X_train = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns = X_train.columns\n",
    ")\n",
    "\n",
    "normalized_X_test = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns = X_test.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes mean score: 0.42 \n",
      "Standard deviation: 0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "cv = 10\n",
    "\n",
    "nb_clf = make_pipeline(StandardScaler(), GaussianNB())\n",
    "nb_score = cross_val_score(nb_clf, X, y.values.ravel(), scoring='accuracy', cv=cv)\n",
    "print(f'Naive Bayes mean score: {nb_score.mean():.2f} \\nStandard deviation: {nb_score.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest mean score: 0.42 \n",
      "Standard deviation: 0.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42))\n",
    "rf_score = cross_val_score(rf_clf, X, y.values.ravel(), scoring='accuracy', cv=cv)\n",
    "print(f'Random Forest mean score: {rf_score.mean():.2f} \\nStandard deviation: {rf_score.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suport Vector Classifier mean score: 0.34 \n",
      "Standard deviation: 0.10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_clf = make_pipeline(StandardScaler(), SVC(random_state=42))\n",
    "svc_score = cross_val_score(svc_clf, X, y.values.ravel(), scoring='accuracy', cv=cv)\n",
    "print(f'Suport Vector Classifier mean score: {svc_score.mean():.2f} \\nStandard deviation: {svc_score.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier mean score: 0.40 \n",
      "Standard deviation: 0.10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_clf = make_pipeline(StandardScaler(), MLPClassifier(random_state=42, max_iter=500))\n",
    "nn_score = cross_val_score(nn_clf, X, y.values.ravel(), scoring='accuracy', cv=cv)\n",
    "print(f'MLP Classifier mean score: {nn_score.mean():.2f} \\nStandard deviation: {nn_score.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "        {\n",
    "            'nn__activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            'nn__solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "            'nn__hidden_layer_sizes': [\n",
    "             (1,),(2,),(3,),(4,),(5,),(6,),(7,),(8,),(9,),(10,),(11,), (12,),(13,),(14,),(15,),(16,),(17,),(18,),(19,),(20,),(21,)\n",
    "             ]\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.506):\n",
      "{'nn__activation': 'relu', 'nn__hidden_layer_sizes': (6,), 'nn__solver': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"nn\", MLPClassifier(random_state=42, max_iter=300))])\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=10, n_jobs=-1)\n",
    "search.fit(X, y)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier mean score: 0.51 \n",
      "Standard deviation: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexj\\actigraphy-classification\\.env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(random_state=42, max_iter=300, hidden_layer_sizes=(6,), solver='sgd')\n",
    "nn_clf = make_pipeline(StandardScaler(), mlp)\n",
    "nn_score = cross_val_score(nn_clf, X, y.values.ravel(), scoring='accuracy', cv=cv)\n",
    "print(f'MLP Classifier mean score: {nn_score.mean():.2f} \\nStandard deviation: {nn_score.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 252 candidates, totalling 2520 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# increasing max_iter\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"nn\", MLPClassifier(random_state=42, max_iter=500))])\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "search.fit(X, y)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
